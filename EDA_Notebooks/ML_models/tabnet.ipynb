{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57e86b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-tabnetNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\vibhanshu jain\\desktop\\client project\\campus-placement-analysis\\eda_notebooks\\ml_models\\tensorflow_env\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vibhanshu jain\\desktop\\client project\\campus-placement-analysis\\eda_notebooks\\ml_models\\tensorflow_env\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vibhanshu jain\\desktop\\client project\\campus-placement-analysis\\eda_notebooks\\ml_models\\tensorflow_env\\lib\\site-packages (from pytorch-tabnet) (1.21.6)\n",
      "Requirement already satisfied: scipy>1.4 in c:\\users\\vibhanshu jain\\desktop\\client project\\campus-placement-analysis\\eda_notebooks\\ml_models\\tensorflow_env\\lib\\site-packages (from pytorch-tabnet) (1.7.3)\n",
      "Collecting tqdm>=4.36\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting torch>=1.3\n",
      "  Downloading torch-2.6.0-cp310-cp310-win_amd64.whl (204.2 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\vibhanshu jain\\desktop\\client project\\campus-placement-analysis\\eda_notebooks\\ml_models\\tensorflow_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\vibhanshu jain\\desktop\\client project\\campus-placement-analysis\\eda_notebooks\\ml_models\\tensorflow_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vibhanshu jain\\desktop\\client project\\campus-placement-analysis\\eda_notebooks\\ml_models\\tensorflow_env\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vibhanshu jain\\desktop\\client project\\campus-placement-analysis\\eda_notebooks\\ml_models\\tensorflow_env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vibhanshu jain\\desktop\\client project\\campus-placement-analysis\\eda_notebooks\\ml_models\\tensorflow_env\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.17.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vibhanshu jain\\desktop\\client project\\campus-placement-analysis\\eda_notebooks\\ml_models\\tensorflow_env\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (3.1.6)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\vibhanshu jain\\desktop\\client project\\campus-placement-analysis\\eda_notebooks\\ml_models\\tensorflow_env\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (4.13.1)\n",
      "Collecting sympy==1.13.1\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\vibhanshu jain\\desktop\\client project\\campus-placement-analysis\\eda_notebooks\\ml_models\\tensorflow_env\\lib\\site-packages (from tqdm>=4.36->pytorch-tabnet) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vibhanshu jain\\desktop\\client project\\campus-placement-analysis\\eda_notebooks\\ml_models\\tensorflow_env\\lib\\site-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.2)\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, tqdm, torch, pytorch-tabnet\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.3.2 mpmath-1.3.0 networkx-3.4.2 pytorch-tabnet-4.1.0 sympy-1.13.1 torch-2.6.0 tqdm-4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/fsspec/\n",
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\VIBHANSHU JAIN\\Desktop\\Client Project\\campus-placement-analysis\\EDA_Notebooks\\ML_models\\tensorflow_env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch-tabnet pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57c78928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE to handle class imbalance...\n",
      "\n",
      "Training Placement Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VIBHANSHU JAIN\\Desktop\\Client Project\\campus-placement-analysis\\EDA_Notebooks\\ML_models\\tensorflow_env\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 1  | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 2  | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 3  | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 4  | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 5  | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 6  | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 7  | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 8  | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 9  | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 10 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 11 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 12 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 13 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 14 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 15 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 16 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 17 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 18 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 19 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 20 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 21 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 22 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 23 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 24 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 25 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 26 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 27 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 28 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 29 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "epoch 30 | loss: 0.0     | val_0_accuracy: 0.54545 | val_0_auc: 0.55238 |  0:00:00s\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 0 and best_val_0_auc = 0.55238\n",
      "\n",
      "Training Salary Regressor...\n",
      "epoch 0  | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 1  | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 2  | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 3  | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 4  | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 5  | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VIBHANSHU JAIN\\Desktop\\Client Project\\campus-placement-analysis\\EDA_Notebooks\\ML_models\\tensorflow_env\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "c:\\Users\\VIBHANSHU JAIN\\Desktop\\Client Project\\campus-placement-analysis\\EDA_Notebooks\\ML_models\\tensorflow_env\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6  | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 7  | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 8  | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 9  | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 10 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 11 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 12 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 13 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 14 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 15 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 16 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 17 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 18 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 19 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 20 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 21 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 22 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 23 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 24 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 25 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 26 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 27 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 28 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 29 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "epoch 30 | loss: 0.0     | val_0_rmse: 17.76452| val_0_mae: 14.73147|  0:00:00s\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 0 and best_val_0_mae = 14.73147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VIBHANSHU JAIN\\Desktop\\Client Project\\campus-placement-analysis\\EDA_Notebooks\\ML_models\\tensorflow_env\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Evaluation ===\n",
      "Placement Accuracy: 0.5455\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         7\n",
      "         1.0       0.63      0.80      0.71        15\n",
      "\n",
      "    accuracy                           0.55        22\n",
      "   macro avg       0.32      0.40      0.35        22\n",
      "weighted avg       0.43      0.55      0.48        22\n",
      "\n",
      "\n",
      "Salary Metrics (for placed students):\n",
      "RMSE: 17.76\n",
      "R² Score: -3.4384\n",
      "\n",
      "=== Placement Feature Importance ===\n",
      "                        Feature  Importance\n",
      "                         tier_2    0.131083\n",
      "                            dsa    0.086642\n",
      "    no_of_programming_languages    0.073214\n",
      "                 dsa_x_projects    0.072105\n",
      "                    internships    0.072021\n",
      "               Machine Learning    0.067882\n",
      "                       gender_M    0.066370\n",
      "                        web_dev    0.065241\n",
      "             cgpa_x_internships    0.045788\n",
      "                           cgpa    0.033630\n",
      "                      inter_gpa    0.029599\n",
      "       is_participate_hackathon    0.029233\n",
      "is_participated_extracurricular    0.028384\n",
      "                     mobile_dev    0.025096\n",
      "                        ssc_gpa    0.024852\n",
      "\n",
      "=== Salary Feature Importance ===\n",
      "                        Feature  Importance\n",
      "                 dsa_x_projects    0.109942\n",
      "                            dsa    0.096886\n",
      "                    internships    0.095270\n",
      "             cgpa_x_internships    0.065902\n",
      "                       gender_M    0.061128\n",
      "               Machine Learning    0.051359\n",
      "       is_participate_hackathon    0.049476\n",
      "is_participated_extracurricular    0.048646\n",
      "                        web_dev    0.045225\n",
      "                        ssc_gpa    0.044244\n",
      "                     mobile_dev    0.041660\n",
      "                         tier_1    0.040192\n",
      "                         tier_2    0.033556\n",
      "                          cloud    0.031202\n",
      "    no_of_programming_languages    0.027448\n",
      "Successfully saved model at placement_model.zip.zip\n",
      "Successfully saved model at salary_model.zip.zip\n",
      "\n",
      "Models saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "import torch\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def print_feature_importance(importance, features, title):\n",
    "    \"\"\"Text-based feature importance display\"\"\"\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    fi_df = pd.DataFrame({'Feature': features, 'Importance': importance})\n",
    "    fi_df = fi_df.sort_values('Importance', ascending=False).head(15)\n",
    "    print(fi_df.to_string(index=False))\n",
    "\n",
    "# 1. Load and prepare data\n",
    "file_path = r'C:\\Users\\VIBHANSHU JAIN\\Desktop\\Client Project\\campus-placement-analysis\\EDA_Notebooks\\datasets\\cleaned_placement_dataset.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Create interaction terms based on your columns\n",
    "data['cgpa_x_internships'] = data['cgpa'] * data['internships']\n",
    "data['dsa_x_projects'] = data['dsa'] * data['no_of_projects']\n",
    "\n",
    "# Separate features and targets\n",
    "X = data.drop(['is_placed', 'salary_as_fresher'], axis=1)\n",
    "y_class = data['is_placed']\n",
    "y_reg = data['salary_as_fresher']\n",
    "\n",
    "# Identify numerical columns (excluding one-hot encoded)\n",
    "num_cols = ['cgpa', 'inter_gpa', 'ssc_gpa', 'internships', 'no_of_projects', \n",
    "            'no_of_programming_languages', 'dsa', 'mobile_dev', 'web_dev', \n",
    "            'Machine Learning', 'cloud', 'cgpa_x_internships', 'dsa_x_projects']\n",
    "\n",
    "# Scale only numerical features\n",
    "scaler = StandardScaler()\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "\n",
    "# 2. Split data\n",
    "X_train, X_test, y_class_train, y_class_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X, y_class, y_reg, test_size=0.15, random_state=42, stratify=y_class\n",
    ")\n",
    "\n",
    "# 3. Handle class imbalance\n",
    "if y_class_train.mean() < 0.4 or y_class_train.mean() > 0.6:\n",
    "    print(\"\\nApplying SMOTE to handle class imbalance...\")\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_class_train = smote.fit_resample(X_train, y_class_train)\n",
    "    # For synthetic samples, set salary to median of placed students\n",
    "    median_salary = y_reg_train[y_reg_train.notna()].median()\n",
    "    y_reg_train = pd.Series(np.where(y_class_train == 1, median_salary, np.nan))\n",
    "\n",
    "# 4. Placement Classifier\n",
    "print(\"\\nTraining Placement Classifier...\")\n",
    "clf = TabNetClassifier(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params={'lr': 2e-2, 'weight_decay': 1e-5},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    scheduler_params={'mode': 'max', 'patience': 5, 'factor': 0.5},\n",
    "    mask_type='sparsemax',\n",
    "    n_steps=5,\n",
    "    n_d=32,\n",
    "    n_a=32,\n",
    "    gamma=1.3,\n",
    "    lambda_sparse=1e-4,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train.values, y_class_train.values,\n",
    "    eval_set=[(X_test.values, y_class_test.values)],\n",
    "    eval_metric=['accuracy', 'auc'],\n",
    "    max_epochs=200,\n",
    "    patience=30,\n",
    "    batch_size=256,\n",
    "    virtual_batch_size=128\n",
    ")\n",
    "\n",
    "# 5. Salary Regressor (only for placed students)\n",
    "placed_train_mask = y_class_train == 1\n",
    "if placed_train_mask.sum() > 0:\n",
    "    print(\"\\nTraining Salary Regressor...\")\n",
    "    reg = TabNetRegressor(\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params={'lr': 2e-2, 'weight_decay': 1e-5},\n",
    "        scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        scheduler_params={'mode': 'min', 'patience': 5, 'factor': 0.5},\n",
    "        n_steps=5,\n",
    "        n_d=32,\n",
    "        n_a=32,\n",
    "        gamma=1.3,\n",
    "        lambda_sparse=1e-4,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    reg.fit(\n",
    "        X_train[placed_train_mask].values,\n",
    "        y_reg_train[placed_train_mask].values.reshape(-1, 1),\n",
    "        eval_set=[(X_test[y_class_test == 1].values, \n",
    "                 y_reg_test[y_class_test == 1].values.reshape(-1, 1))],\n",
    "        eval_metric=['rmse', 'mae'],\n",
    "        max_epochs=200,\n",
    "        patience=30,\n",
    "        batch_size=256,\n",
    "        virtual_batch_size=128\n",
    "    )\n",
    "\n",
    "# 6. Evaluation\n",
    "print(\"\\n=== Model Evaluation ===\")\n",
    "y_class_pred = clf.predict(X_test.values)\n",
    "print(f\"Placement Accuracy: {accuracy_score(y_class_test, y_class_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_class_test, y_class_pred))\n",
    "\n",
    "placed_test_mask = y_class_test == 1\n",
    "if placed_test_mask.sum() > 0 and 'reg' in locals():\n",
    "    y_reg_pred = reg.predict(X_test[placed_test_mask].values)\n",
    "    print(\"\\nSalary Metrics (for placed students):\")\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_reg_test[placed_test_mask], y_reg_pred)):.2f}\")\n",
    "    print(f\"R² Score: {r2_score(y_reg_test[placed_test_mask], y_reg_pred):.4f}\")\n",
    "\n",
    "# 7. Feature Importance\n",
    "print_feature_importance(clf.feature_importances_, X.columns, \"Placement Feature Importance\")\n",
    "if 'reg' in locals():\n",
    "    print_feature_importance(reg.feature_importances_, X.columns, \"Salary Feature Importance\")\n",
    "\n",
    "# 8. Save models\n",
    "clf.save_model('placement_model.zip')\n",
    "if 'reg' in locals():\n",
    "    reg.save_model('salary_model.zip')\n",
    "print(\"\\nModels saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_env)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
