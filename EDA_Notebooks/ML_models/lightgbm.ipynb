{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8496ff9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SMOTE to handle class imbalance...\n",
      "\n",
      "Training Placement Classifier...\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\tvalid_0's auc: 0.980952\tvalid_0's binary_logloss: 0.493767\n",
      "[20]\tvalid_0's auc: 0.971429\tvalid_0's binary_logloss: 0.387683\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.980952\tvalid_0's binary_logloss: 0.575911\n",
      "\n",
      "Training Salary Predictor with 84 samples...\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\tvalid_0's l2: 2.55109\n",
      "[20]\tvalid_0's l2: 2.38383\n",
      "[30]\tvalid_0's l2: 2.2746\n",
      "[40]\tvalid_0's l2: 2.19475\n",
      "[50]\tvalid_0's l2: 2.12448\n",
      "[60]\tvalid_0's l2: 2.07353\n",
      "[70]\tvalid_0's l2: 2.01893\n",
      "[80]\tvalid_0's l2: 1.9792\n",
      "[90]\tvalid_0's l2: 1.95289\n",
      "[100]\tvalid_0's l2: 1.93801\n",
      "[110]\tvalid_0's l2: 1.94186\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's l2: 1.93607\n",
      "\n",
      "=== Evaluation ===\n",
      "\n",
      "Placement Accuracy: 0.9091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.71      0.83         7\n",
      "         1.0       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.91        22\n",
      "   macro avg       0.94      0.86      0.89        22\n",
      "weighted avg       0.92      0.91      0.90        22\n",
      "\n",
      "\n",
      "Salary Prediction Results:\n",
      "RMSE: 7.25\n",
      "R²: 0.2611\n",
      "MAE: 5.32\n",
      "\n",
      "Placement Feature Importance:\n",
      "                    Feature  Importance\n",
      "          academic_strength           7\n",
      "                 tier_score           5\n",
      "no_of_programming_languages           3\n",
      "                core_skills           0\n",
      "           experience_score           0\n",
      "   is_participate_hackathon           0\n",
      "\n",
      "Salary Feature Importance:\n",
      "                    Feature  Importance\n",
      "                 tier_score         167\n",
      "          academic_strength         154\n",
      "                core_skills          64\n",
      "no_of_programming_languages          48\n",
      "           experience_score          23\n",
      "   is_participate_hackathon           0\n"
     ]
    }
   ],
   "source": [
    "# Install LightGBM if not available\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except ImportError:\n",
    "    !pip install lightgbm\n",
    "    import lightgbm as lgb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import (accuracy_score, classification_report, \n",
    "                           mean_squared_error, r2_score, mean_absolute_error)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. Load and prepare data\n",
    "file_path = r'C:\\Users\\VIBHANSHU JAIN\\Desktop\\Client Project\\campus-placement-analysis\\EDA_Notebooks\\datasets\\cleaned_placement_dataset.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Feature engineering\n",
    "data['tier_score'] = data['tier_1']*1.5 + data['tier_2']*1.0 + data['tier_3']*0.5\n",
    "data['core_skills'] = data['dsa']*0.5 + data['web_dev']*0.3 + data['mobile_dev']*0.2\n",
    "data['academic_strength'] = data['cgpa']*0.7 + data['inter_gpa']*0.2 + data['ssc_gpa']*0.1\n",
    "data['experience_score'] = np.log1p(data['internships']) * np.sqrt(data['no_of_projects']+1)\n",
    "\n",
    "# Separate features and targets\n",
    "X = data[['tier_score', 'core_skills', 'academic_strength', 'experience_score',\n",
    "         'no_of_programming_languages', 'is_participate_hackathon']]\n",
    "y_class = data['is_placed']\n",
    "y_reg = data['salary_as_fresher']\n",
    "\n",
    "# 2. Split data\n",
    "X_train, X_test, y_class_train, y_class_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X, y_class, y_reg, test_size=0.15, random_state=42, stratify=y_class\n",
    ")\n",
    "\n",
    "# 3. Handle class imbalance\n",
    "if y_class_train.mean() < 0.4 or y_class_train.mean() > 0.6:\n",
    "    print(\"Applying SMOTE to handle class imbalance...\")\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_class_train = smote.fit_resample(X_train, y_class_train)\n",
    "    # Align y_reg_train with resampled X_train\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    y_reg_train = y_reg_train.reset_index(drop=True)\n",
    "    y_reg_train = pd.concat([y_reg_train, pd.Series([np.nan]*(len(X_train)-len(y_reg_train)))])\n",
    "\n",
    "# 4. Placement Classifier\n",
    "print(\"\\nTraining Placement Classifier...\")\n",
    "lgb_classifier = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    num_leaves=31,\n",
    "    min_child_samples=20,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_classifier.fit(X_train, y_class_train,\n",
    "                  eval_set=[(X_test, y_class_test)],\n",
    "                  eval_metric='auc',\n",
    "                  callbacks=[lgb.early_stopping(stopping_rounds=20),\n",
    "                            lgb.log_evaluation(period=10)])\n",
    "\n",
    "# 5. Salary Prediction (Only for placed students)\n",
    "placed_train_mask = y_class_train == 1\n",
    "placed_test_mask = y_class_test == 1\n",
    "\n",
    "if placed_train_mask.sum() > 10:\n",
    "    print(f\"\\nTraining Salary Predictor with {placed_train_mask.sum()} samples...\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train_placed = X_train[placed_train_mask].reset_index(drop=True)\n",
    "    y_reg_train_placed = y_reg_train[placed_train_mask].reset_index(drop=True)\n",
    "    \n",
    "    # Remove samples with NaN salaries\n",
    "    valid_samples = ~y_reg_train_placed.isna()\n",
    "    X_train_placed = X_train_placed.loc[valid_samples]\n",
    "    y_reg_train_placed = y_reg_train_placed[valid_samples]\n",
    "    \n",
    "    if len(y_reg_train_placed) > 10:\n",
    "        # Handle outliers\n",
    "        upper_clip = y_reg_train_placed.quantile(0.95)\n",
    "        y_reg_train_placed = y_reg_train_placed.clip(upper=upper_clip)\n",
    "        \n",
    "        # Transform data\n",
    "        qt = QuantileTransformer(output_distribution='normal')\n",
    "        y_reg_train_transformed = qt.fit_transform(y_reg_train_placed.values.reshape(-1, 1)).ravel()\n",
    "        \n",
    "        # Prepare evaluation set\n",
    "        X_test_placed = X_test[placed_test_mask]\n",
    "        y_test_placed = y_reg_test[placed_test_mask]\n",
    "        \n",
    "        if len(y_test_placed) > 0:\n",
    "            y_test_transformed = qt.transform(y_test_placed.values.reshape(-1, 1)).ravel()\n",
    "            eval_set = [(X_test_placed, y_test_transformed)]\n",
    "        else:\n",
    "            eval_set = None\n",
    "        \n",
    "        # Train model\n",
    "        lgb_regressor = lgb.LGBMRegressor(\n",
    "            objective='regression',\n",
    "            n_estimators=150,\n",
    "            learning_rate=0.01,\n",
    "            max_depth=3,\n",
    "            num_leaves=7,\n",
    "            min_child_samples=10,\n",
    "            reg_alpha=1.0,\n",
    "            reg_lambda=1.0,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=-1\n",
    "        )\n",
    "        \n",
    "        if eval_set:\n",
    "            lgb_regressor.fit(X_train_placed, y_reg_train_transformed,\n",
    "                            eval_set=eval_set,\n",
    "                            callbacks=[lgb.early_stopping(stopping_rounds=20),\n",
    "                                      lgb.log_evaluation(period=10)])\n",
    "        else:\n",
    "            lgb_regressor.fit(X_train_placed, y_reg_train_transformed)\n",
    "\n",
    "# 6. Evaluation\n",
    "print(\"\\n=== Evaluation ===\")\n",
    "# Placement evaluation\n",
    "y_class_pred = lgb_classifier.predict(X_test)\n",
    "print(f\"\\nPlacement Accuracy: {accuracy_score(y_class_test, y_class_pred):.4f}\")\n",
    "print(classification_report(y_class_test, y_class_pred))\n",
    "\n",
    "# Salary evaluation\n",
    "if placed_test_mask.sum() > 0 and 'lgb_regressor' in locals():\n",
    "    try:\n",
    "        y_pred_transformed = lgb_regressor.predict(X_test[placed_test_mask])\n",
    "        y_pred = qt.inverse_transform(y_pred_transformed.reshape(-1, 1))\n",
    "        \n",
    "        print(\"\\nSalary Prediction Results:\")\n",
    "        print(f\"RMSE: {np.sqrt(mean_squared_error(y_reg_test[placed_test_mask], y_pred)):.2f}\")\n",
    "        print(f\"R²: {r2_score(y_reg_test[placed_test_mask], y_pred):.4f}\")\n",
    "        print(f\"MAE: {mean_absolute_error(y_reg_test[placed_test_mask], y_pred):.2f}\")\n",
    "        \n",
    "        if r2_score(y_reg_test[placed_test_mask], y_pred) < 0:\n",
    "            print(\"\\nFalling back to mean prediction due to negative R²\")\n",
    "            mean_pred = np.full_like(y_reg_test[placed_test_mask], y_reg_train_placed.mean())\n",
    "            print(f\"Mean predictor R²: {r2_score(y_reg_test[placed_test_mask], mean_pred):.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in salary evaluation: {str(e)}\")\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\nPlacement Feature Importance:\")\n",
    "print(pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': lgb_classifier.feature_importances_\n",
    "}).sort_values('Importance', ascending=False).to_string(index=False))\n",
    "\n",
    "if 'lgb_regressor' in locals():\n",
    "    print(\"\\nSalary Feature Importance:\")\n",
    "    print(pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': lgb_regressor.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_env)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
