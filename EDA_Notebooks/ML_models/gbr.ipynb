{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4989537a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 79 placed students...\n",
      "\n",
      "=== Evaluation Results ===\n",
      "Random Forest R²: 0.5074\n",
      "Gradient Boosting R²: 0.3538\n",
      "Ensemble R²: 0.4315\n",
      "\n",
      "Error Analysis:\n",
      "Median Salary: 11.50\n",
      "MAE: 3.95\n",
      "Error Range: -9.15 to 13.32\n",
      "\n",
      "Top Predictive Features:\n",
      "         Feature  Importance\n",
      "     skill_score    0.391258\n",
      "  academic_power    0.264174\n",
      "  project_impact    0.101887\n",
      "experience_score    0.094109\n",
      "          tier_3    0.079343\n",
      "          tier_1    0.046178\n",
      "          tier_2    0.023051\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. Load and prepare data\n",
    "file_path = r'C:\\Users\\VIBHANSHU JAIN\\Desktop\\Client Project\\campus-placement-analysis\\EDA_Notebooks\\datasets\\cleaned_placement_dataset.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 2. Enhanced Feature Engineering\n",
    "data['skill_score'] = (0.4*data['dsa'] + 0.2*data['web_dev'] + \n",
    "                      0.2*data['mobile_dev'] + 0.1*data['Machine Learning'] + \n",
    "                      0.1*data['cloud'])\n",
    "data['academic_power'] = (0.6*data['cgpa'] + 0.3*data['inter_gpa'] + 0.1*data['ssc_gpa'])\n",
    "data['project_impact'] = data['no_of_projects'] * data['no_of_programming_languages']\n",
    "data['experience_score'] = np.log1p(data['internships']) * data['no_of_projects']\n",
    "\n",
    "# 3. Prepare data\n",
    "X = data[['skill_score', 'academic_power', 'project_impact', \n",
    "          'experience_score', 'tier_1', 'tier_2', 'tier_3']]\n",
    "y = data['salary_as_fresher']\n",
    "placed_mask = data['is_placed'] == 1\n",
    "\n",
    "# 4. Train-test split ONLY on placed students\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X[placed_mask], y[placed_mask], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 5. Model Training - Ensemble Approach\n",
    "print(f\"\\nTraining with {len(X_train)} placed students...\")\n",
    "\n",
    "# Impute missing salaries with median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "y_train_imputed = imputer.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Model 1: Random Forest with optimized parameters\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=7,\n",
    "    min_samples_leaf=5,\n",
    "    max_features=0.6,\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train, y_train_imputed)\n",
    "\n",
    "# Model 2: Gradient Boosting\n",
    "gbr = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42\n",
    ")\n",
    "gbr.fit(X_train, y_train_imputed)\n",
    "\n",
    "# 6. Ensemble Prediction\n",
    "rf_pred = rf.predict(X_test)\n",
    "gbr_pred = gbr.predict(X_test)\n",
    "ensemble_pred = 0.7*gbr_pred + 0.3*rf_pred  # Weighted ensemble\n",
    "\n",
    "# 7. Comprehensive Evaluation\n",
    "print(\"\\n=== Evaluation Results ===\")\n",
    "print(f\"Random Forest R²: {r2_score(y_test, rf_pred):.4f}\")\n",
    "print(f\"Gradient Boosting R²: {r2_score(y_test, gbr_pred):.4f}\")\n",
    "print(f\"Ensemble R²: {r2_score(y_test, ensemble_pred):.4f}\")\n",
    "\n",
    "print(\"\\nError Analysis:\")\n",
    "errors = y_test - ensemble_pred\n",
    "print(f\"Median Salary: {np.median(y_test):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, ensemble_pred):.2f}\")\n",
    "print(f\"Error Range: {errors.min():.2f} to {errors.max():.2f}\")\n",
    "\n",
    "# 8. Feature Importance\n",
    "print(\"\\nTop Predictive Features:\")\n",
    "importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': gbr.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "print(importance.to_string(index=False))\n",
    "\n",
    "# 9. Final Recommendations\n",
    "if r2_score(y_test, ensemble_pred) < 0.3:\n",
    "    print(\"\\nWarning: Model still performing poorly. Recommendations:\")\n",
    "    print(\"1. Collect more salary data (minimum 100 placed students recommended)\")\n",
    "    print(\"2. Add more salary-determining features (company type, job role, etc.)\")\n",
    "    print(\"3. Consider converting to classification (salary ranges instead of exact values)\")\n",
    "    print(\"4. Verify salary data quality - remove extreme outliers if present\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_env)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
